{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accidents.mp4\" \n",
    "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x206711c83a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_ID  Class\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      1\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 46s 8s/step\n",
      "3/3 [==============================] - 17s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((155, 7, 7, 512), (67, 7, 7, 512))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(67, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 5s 620ms/step - loss: 0.7707 - accuracy: 0.5806 - val_loss: 0.7021 - val_accuracy: 0.6716\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 2s 504ms/step - loss: 0.3130 - accuracy: 0.8968 - val_loss: 0.8227 - val_accuracy: 0.7015\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 3s 558ms/step - loss: 0.2204 - accuracy: 0.8968 - val_loss: 0.8611 - val_accuracy: 0.7015\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 3s 588ms/step - loss: 0.1254 - accuracy: 0.9677 - val_loss: 0.8102 - val_accuracy: 0.7761\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 3s 543ms/step - loss: 0.0901 - accuracy: 0.9871 - val_loss: 0.7722 - val_accuracy: 0.7761\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 3s 531ms/step - loss: 0.0562 - accuracy: 0.9935 - val_loss: 0.8203 - val_accuracy: 0.7463\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 3s 540ms/step - loss: 0.0446 - accuracy: 0.9935 - val_loss: 0.7919 - val_accuracy: 0.7612\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 3s 528ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.7463\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 3s 520ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7910\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 3s 527ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.7612\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 3s 554ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.8277 - val_accuracy: 0.7612\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 3s 588ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.7463\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 3s 542ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.8257 - val_accuracy: 0.7761\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 2s 504ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.7463\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 3s 524ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.7612\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 3s 574ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.8401 - val_accuracy: 0.7612\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 3s 558ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8359 - val_accuracy: 0.7612\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 3s 714ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8418 - val_accuracy: 0.7612\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 3s 733ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.7612\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8474 - val_accuracy: 0.7612\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8494 - val_accuracy: 0.7761\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 4s 728ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.7761\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 3s 690ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8581 - val_accuracy: 0.7761\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 3s 697ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.7612\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8624 - val_accuracy: 0.7612\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 3s 701ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.7612\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 4s 738ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.7910\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 4s 737ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.7910\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 7s 2s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8709 - val_accuracy: 0.8060\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 3s 676ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 3s 721ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.7761\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 4s 730ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8817 - val_accuracy: 0.7910\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 4s 732ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8830 - val_accuracy: 0.7910\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 4s 760ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.7910\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 4s 753ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8890 - val_accuracy: 0.7910\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 5s 984ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.7910\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 4s 742ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8946 - val_accuracy: 0.7910\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 3s 703ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8955 - val_accuracy: 0.7910\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 3s 616ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.7910\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 3s 586ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.7910\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 3s 513ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.7910\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 2s 509ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.7910\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 3s 556ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9041 - val_accuracy: 0.7910\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 3s 515ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9076 - val_accuracy: 0.7910\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 3s 533ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9107 - val_accuracy: 0.7910\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 3s 497ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.7910\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 3s 529ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9141 - val_accuracy: 0.7910\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 3s 520ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.8060\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 3s 580ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.7910\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 3s 538ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.7910\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 3s 572ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.7910\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 3s 599ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.7910\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 3s 588ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 3s 559ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9293 - val_accuracy: 0.8060\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 3s 564ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8060\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 3s 505ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.8060\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 3s 596ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.8060\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 3s 558ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9364 - val_accuracy: 0.8060\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 3s 519ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.8060\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 3s 610ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.8209\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 3s 544ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.8209\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 3s 587ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8209\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 3s 620ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8060\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 3s 614ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.8060\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 3s 613ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9474 - val_accuracy: 0.8060\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 3s 705ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.8060\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 3s 693ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9518 - val_accuracy: 0.8060\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 3s 661ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.8060\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 3s 629ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.8060\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 3s 592ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.8060\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 3s 599ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.8060\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 3s 651ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.8060\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 3s 575ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.8060\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 3s 579ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.8060\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 3s 549ms/step - loss: 9.8367e-04 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.8060\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 3s 569ms/step - loss: 9.6178e-04 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.8060\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 3s 672ms/step - loss: 9.3900e-04 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.8060\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 4s 828ms/step - loss: 9.1921e-04 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.8060\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 3s 490ms/step - loss: 9.0119e-04 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.8060\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 2s 426ms/step - loss: 8.7791e-04 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.8060\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 2s 450ms/step - loss: 8.6295e-04 - accuracy: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.8060\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 2s 426ms/step - loss: 8.4287e-04 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.8060\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 2s 436ms/step - loss: 8.2655e-04 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.8060\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 2s 431ms/step - loss: 8.0816e-04 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.8060\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 2s 440ms/step - loss: 7.9145e-04 - accuracy: 1.0000 - val_loss: 0.9794 - val_accuracy: 0.8060\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 2s 458ms/step - loss: 7.7477e-04 - accuracy: 1.0000 - val_loss: 0.9809 - val_accuracy: 0.8060\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 7.6097e-04 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.8060\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 3s 577ms/step - loss: 7.4663e-04 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.8060\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 2s 449ms/step - loss: 7.3168e-04 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.8060\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 2s 488ms/step - loss: 7.1799e-04 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.8060\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 2s 500ms/step - loss: 7.0557e-04 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.8060\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 2s 521ms/step - loss: 6.8980e-04 - accuracy: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.8060\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 2s 453ms/step - loss: 6.7924e-04 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.8060\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 6.6589e-04 - accuracy: 1.0000 - val_loss: 0.9920 - val_accuracy: 0.8060\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 2s 475ms/step - loss: 6.5322e-04 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.8060\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 2s 472ms/step - loss: 6.4085e-04 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.8060\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 6.2892e-04 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.8060\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 2s 449ms/step - loss: 6.1869e-04 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.8060\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 6.0837e-04 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.8060\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 2s 472ms/step - loss: 5.9805e-04 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206991f8c40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accident-1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 7, 7, 512)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image.reshape(9, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 226ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.7242524e-06 9.9999523e-01]\n",
      " [2.7481889e-04 9.9972516e-01]\n",
      " [3.5377364e-03 9.9646229e-01]\n",
      " [1.2143134e-03 9.9878567e-01]\n",
      " [3.4265642e-03 9.9657345e-01]\n",
      " [5.6425166e-01 4.3574831e-01]\n",
      " [8.1339675e-01 1.8660328e-01]\n",
      " [6.6698730e-01 3.3301270e-01]\n",
      " [8.6766672e-01 1.3233325e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,9):\n",
    "    if predictions[i][0]<predictions[i][1]:\n",
    "        print(\"No Accident\")\n",
    "    else:\n",
    "        print(\"Accident\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "#g = geocoder.ip('me')\n",
    "#locname = geoLoc.reverse(g.latlng)\n",
    "#account_sid =AC187242aa79c3a52a68a137cf5abf56d4   #Enter Your account sid\n",
    "#auth_token = 0da39bf4bf29d6c1d8c9d876c95e8425 #Enter your auth token\n",
    "#client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Accident-1.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            predict=\"No Accident\"\n",
    "        else:\n",
    "            predict=\"Accident\"\n",
    "            flag=1\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "#if flag==1:\n",
    "    #client.messages.create(\n",
    "                # body=\"Accident detected in \"+locname.address,\n",
    "                # from_= #Enter your virtual phone number,\n",
    "                # to= #Enter phone number which you have to send the SMS. )\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66eba28a75a64fbe1a9b9c30d27f7c856726c51cbbef86297708eae4ce175db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
